---
title: "R for SAS users"
author: "Quentin D. Read"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---

```{r sas and rmarkdown setup, include = FALSE}
library(SASmarkdown)
saspath <- "C:\\Program Files\\SASHome\\SASFoundation\\9.4\\sas.exe"
sasopts <- "-nosplash -ls 75"
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(
  engine.path = 
    list(sas = saspath, sashtml5 = saspath),
  engine.opts = 
    list(sas = sasopts, sashtml5 = sasopts)
)
```

# Introduction

## What is this workshop?

This workshop is intended for SAS users who want to learn R. The people who will get the most out of this course are practicing researchers who have a decent working knowledge of SAS, and of basic statistical analysis (descriptive stats and regression models) as it applies to their field. 

[Download the worksheet for this lesson here](https://quentinread.com/SEAStats/brms_crash_course/brms_crash_course_worksheet.R).

*A word of warning*: I have much more experience working with R compared to SAS. So if you notice any issues or glaring flaws in the SAS code, chalk that up to my poor SAS skills! The SAS code is provided here mainly for comparison purposes, so that you will be able to better understand what the R code is trying to do by comparing it to a familiar bit of SAS code.

## What will you learn from this workshop?

### Conceptual learning objectives

During this workshop, you will ...

- Learn the similarities and differences between SAS and R, both different tools for the job
- Get introduced to what R packages are, in particular the "tidyverse"
- Learn which common SAS statistical procedures correspond to which R packages/functions
- Learn about R and SAS' capabilities for Bayesian model fitting, and generating pretty reports and presentations

### Practical skills

In this workshop, participants will go through a "data to doc" pipeline in R, comparing R code to SAS code each step of the way. As you go through the pipeline, you will ...

- Import the data from a CSV file
- Clean and reshape the data
- Calculate some summary statistics and make some exploratory plots
- Fit a linear model, a generalized linear model, and a generalized linear mixed-effects model
- Make post hoc comparisons
- Make plots and tables of results

## How to follow along with this workshop

- Slides and text version of lessons are online
- Fill in code in the worksheet (replace `...` with code)
- You can always copy and paste code from text version of lesson if you fall behind
- Notes on best practices will be marked with **PROTIP** as we go along!

# Background

## R versus SAS

- SAS has been around longer than R (spun off from NC State in 1976, while R was first released in 1993)
- R is free and open-source. This is honestly an unalloyed advantage for R
- SAS is top-down, R is decentralized. This has pros and cons
- R has a diversity of packages, with a lot of different uses, and develops more quickly
- The main other alternative is Python which seems to be more common in "data science" versus "stats," and industry versus academia/government

The bottom line is that they are both tools that can be used to do a job. Neither is perfect and they both have advantages and disadvantages. Some people prefer one to the other, and some people have more experience with one than the other. But I strongly recommend that new ARS researchers just starting their "stats and data science journey" begin with R. This is thanks to its superiority for open and reproducible science, the fact that it is free and thus you will be able to use it even if you move to an institution that doesn't have a SAS subscription, its greater diversity of tools and bag of tricks, and because it just does some stuff flat out better.

All of that said, the point of this workshop is not to convert people from SAS to R. It is simply to give SAS users some exposure to R functionality and demonstrate how you can translate familiar statistical procedures in SAS into R.

## R packages

What are they?

INSERT TEXT HERE

## SAS procedures vs. R packages/functions: an overview table

There are a diversity of R packages and functions for each of these tasks but I am showing you my "favorite" or recommended alternatives in bold.

```{r, echo = FALSE}

```


INSERT TABLE HERE

Okay, that's enough lecturing. Let's actually do some coding.

# Data to doc pipeline

A typical "pipeline" to get from raw data at one end, to a finished document (report or presentation) at the other, includes the following steps, whether you are working in SAS or R.

- Import the data from a file
- Clean, manipulate, and sort the data
- Make exploratory graphs and tables
- Fit statistical models
- Look at model diagnostics to make sure our models are valid
- Extract predictions from the statistical models
- Make graphs and tables of model predictions
- Put results into a document

We will go through each step of the pipeline. In each step, first we'll look at some SAS code that does a particular thing (without going into detailed explanation of how the SAS code works), then we'll co-create some R code that does that same thing while explaining in detail how each bit of the R code works.

We will use example datasets for this lesson from the R package [**agridat**](https://kwstat.github.io/agridat/), which is a curated collection of datasets from agricultural sciences. (You can learn a lot from it whether or not you are an "R person!")

## Load R packages

Here we'll load the R packages we are going to work with today. 

> **PROTIP**: It's good practice to load all necessary packages for a script at the beginning. Among other benefits, this ensures that if anyone who's running the script needs to install one or more packages to run your script, they can do that all at once instead of having to interrupt the workflow later to install packages.

```{r}
library(tidyverse)
```


## Import the data from a file

The example data for this lesson are hosted on GitHub. 

> **PROTIP**: Notice the data are in CSV (comma-separated values) format. Although both SAS and R have the capability to read data directly from Microsoft Excel files (.xlsx), I recommend using CSV wherever possible. This is a good idea for a couple reasons: first, it is a plain-text format that works on any operating system, and is not a proprietary Microsoft format. Also, it does not allow formatting so you can't be tempted to encode important information in formatting. For example, highlighting cells to flag them -- a better way would be to add an additional column with a text label for the flag that can be read in to SAS or R more easily.

### SAS: `proc import`

Some people like to import data in the `data` step in SAS, or use `datalines;`, but I recommend using `proc import`.

```{sashtml5, collectcode = TRUE, SASecho = FALSE}
ods html5 style = htmlblue;
filename csvFile url "https://github.com/qdread/R-for-SAS-users/raw/main/data/NASS_soybean.csv";
proc import datafile=csvFile out=nass_soybeans replace dbms=csv; guessingrows=2000; run;
```

### R: `read_csv`

```{r}
nass_soybeans <- read_csv('https://github.com/qdread/R-for-SAS-users/raw/main/data/NASS_soybean.csv')
```
## Clean, manipulate, and sort the data

First, let's look at what we are working with. The SAS "dataset" `nass_soybeans` and the R "data frame" `nass_soybeans` are very similar objects. They both have ~2500 rows of data and 4 named columns.

```{sashtml5, collectcode = TRUE, SASecho = FALSE}
proc print data = nass_soybeans(obs = 10); run;
proc contents data = nass_soybeans; run;
```

```{r}
head(nass_soybeans, 10)
summary(nass_soybeans)
glimpse(nass_soybeans)
```

Let's say we wanted to work with only the data from the states in the Southeast region. In SAS we usually use the `data` step to create subsets of the data, whereas in R tidyverse, we use the `filter()` function from the **dplyr** package. FIXME MORE WORDS

```{sashtml5, collectcode = TRUE, SASecho = FALSE}
data se_soybeans; set nass_soybeans;
	where state in ('Alabama', 'Arkansas', 'Florida', 'Georgia', 'Louisiana', 'Mississippi', 'North Carolina', 'South Carolina', 'Tennessee');
run;
```

```{r}
se_states <- c('Alabama', 'Arkansas', 'Florida', 'Georgia', 'Louisiana', 'Mississippi', 'North Carolina', 'South Carolina', 'Tennessee')

se_soybeans <- filter(nass_soybeans, state %in% se_states)
```

use data step and mutate to create a total_yield column FIXME MORE AND BETTER WORDS

```{sashtml5, collectcode = TRUE, SASecho = FALSE}
data se_soybeans; set se_soybeans;
	total_yield = acres * yield;
run;
```

```{r}
se_soybeans <- mutate(se_soybeans, total_yield = acres * yield)
```

We can make this more concise in both SAS and R. In SAS, we would combine the row subsetting and the operation to create a new calculated column into the same `data` step. In R, we can put them into one statement by using the "pipe" operator: `%>%`. FIXMEEEEE MORE WORDS

```{sashtml5, collectcode = TRUE, SASecho = FALSE}
data se_soybeans; set nass_soybeans;
  where state in ('Alabama', 'Arkansas', 'Florida', 'Georgia', 'Louisiana', 'Mississippi', 'North Carolina', 'South Carolina', 'Tennessee');
	total_yield = acres * yield;
run;
```

```{r}
se_soybeans <- nass_soybeans %>%
  filter(state %in% se_states) %>%
  mutate(total_yield = acres * yield)
```

Finally, our data is sorted first by state and then by year. Let's say we wanted to sort the rows first by year and then by state. We can sort the data in SAS using `proc sort`. In R tidyverse, we can use the `arrange()` function from **dplyr**. 

```{sashtml5, collectcode = TRUE, SASecho = FALSE}
proc sort data = se_soybeans;
	by year state;
run;
```

```{r}
se_soybeans <- arrange(se_soybeans, year, state)
```

We can even put the `filter()`, `mutate()`, and `arrange()` operations into the same pipe statement.

```{r}
se_soybeans <- nass_soybeans %>%
  filter(state %in% se_states) %>%
  mutate(total_yield = acres * yield) %>%
  arrange(year, state)
```

This dataset is in a format where each row is a unique observation: measurements of soybean harvested acreage and yield in bushels per acre, identified by a unique combination of year and state. The R tidyverse packages call this format "tidy" data.

However, the long and skinny format of most "tidy" datasets is not ideal for visualizing the data in a table. We might want to reshape the data into wide format. In SAS we might use `proc transpose`, while in R tidyverse we use `pivot_wider()`. Let's do this for only the `total_yield` column with the years going down the rows and the states each getting a separate column. 

Notice how the SAS and R statements are really pretty similar, it's just slightly different syntax and different names of the arguments. For example in `proc transpose` the `id` means which column will identify the columns, whereas in `pivot_wider()`, `id_cols` means which column will identify the rows!

```{sashtml5, collectcode = TRUE, SASecho = FALSE}
proc transpose data = se_soybeans out = total_yield_wide;
	by year; id state; var total_yield;
run;
```

```{r}
total_yield_wide <- se_soybeans %>%
  pivot_wider(id_cols = year, names_from = state, values_from = total_yield)
```

> **PROTIP**: With `proc transpose`, we had to make sure the data was sorted by year and then state to transpose it in this way, so that the `by` groups are in contiguous blocks. R's `pivot_wider()` has no such requirement.

Later I'll show how to display this in a "pretty" format.

We can pivot from a wide to a long format as well. In SAS we'd use `proc transpose` again, versus `pivot_longer()` in R tidyverse.

```{sashtml5, collectcode = TRUE, SASecho = FALSE}
proc transpose data = total_yield_wide out = total_yield_long;
	by year;
run;
```

```{r}
total_yield_long <- total_yield_wide %>%
  pivot_longer(-year, names_to = 'state', values_to = 'total_yield')
```

Notice in both cases we get more rows than we started with because Florida is missing data for some of the years. Those rows with missing data are now explicitly included in the new long-format dataset/data frame. Also note that in SAS you would have to do an additional `data` step to rename the columns to what they were before; in R we can do this more easily inside the `pivot_longer()` statement.

## Make exploratory graphs

There are a lot of books and online tutorials out there about how to make great data visualizations in R, so here I'll just provide you a couple of examples. Let's say we wanted to plot the time series of total yield for four of the states as different colored lines on the same plot, with a log scale y axis. Here is a way to do it in SAS.

```{sashtml5, collectcode = TRUE, SASecho = FALSE}
proc sgplot data=se_soybeans;
	where state in ('Arkansas', 'Tennessee', 'North Carolina', 'Georgia');
	series x=year y=total_yield / group=state; 
	yaxis type=log label='total yield (bu)';
run;
```

And in R, we use `ggplot()`.

```{r}
fourstates <- filter(se_soybeans, state %in% c('Arkansas', 'Tennessee', 'North Carolina', 'Georgia'))

ggplot(fourstates, aes(x = year, y = total_yield, color = state)) +
  geom_line(linewidth = 1) +
  theme_bw() +
  scale_y_log10()
```

Alternatively, we could plot each of the time series on a separate panel. In SAS this requires a separate procedure but in R the existing `ggplot()` statement can be modified.

```{sashtml5, collectcode = TRUE, SASecho = FALSE}
proc sgpanel data=se_soybeans;
	where state in ('Arkansas', 'Tennessee', 'North Carolina', 'Georgia');
	panelby state;
	series x=year y=total_yield;
	rowaxis type=log label='total yield (bu)';
run;
```

```{r}
ggplot(fourstates, aes(x = year, y = total_yield)) +
  facet_wrap(~ state) +
  geom_line(linewidth = 1) +
  theme_bw() +
  scale_y_log10()
```


## Make tables of summary statistics

Let's say we want to know the total acreage harvested per year, the total yield in bushels, and the weighted mean of yield per acre across states (weighted by acreage harvested), for every 10th year. In SAS we can use `proc sql` to do this -- there are other ways but that's probably the most concise. In R tidyverse, we can calculate those different summary stats with a piped statement: `filter()` to retain only the rows where year is divisible by 10, `group_by()` to identify the column by which we're grouping the data, and `summarize()` which contains a comma-separated list of summary statistics to calculate. 

> **PROTIP**: Notice the similarities between `proc sql` and the R tidyverse code. That's because the tidyverse syntax was partially inspired by SQL.

> **PROTIP 2**: Notice that in SAS, a single equal sign `=` is used to test whether two values are equal, while in R (and in many other languages such as C and Python) you use the double equal sign `==`.

```{sashtml5, collectcode = TRUE, SASecho = FALSE}
proc sql;
	select 
		year,
		sum(acres) as grand_total_acres,
		sum(total_yield) as grand_total_yield,
		sum(yield * acres) / sum(acres) as mean_yield
	from se_soybeans
	where mod(year, 10) = 0
	group by year;
quit;
```

```{r}
yearly_totals <- se_soybeans %>%
  filter(year %% 10 == 0) %>%
  group_by(year) %>%
  summarize(
    grand_total_acres = sum(acres),
    grand_total_yield = sum(total_yield),
    mean_yield = weighted.mean(yield, acres)
  )

yearly_totals
```


## Fit statistical models

Here's where things get interesting. We can fit all kinds of different statistical models. Let's say we want to fit a linear mixed model to the total yield data, to determine if there is a linear trend in the 

We can also fit a repeated measures error structure.

Finally, we can fit GAMs as well.

### Look at model diagnostics

## Extract predictions from models

## Make graphs and tables of model predictions

## Put results into a document